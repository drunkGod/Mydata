z 

# 四、中间件

## 1.redis

### 1.1 Redis数据类型

• Redis用过哪些数据数据，以及Redis底层怎么实现
• Redis的数据结构 最常问 hash是什么， sorted set怎么实现的

Redis有下列五种数据类型：

string（字符串），list（链表），set（集合），zset（sorted set - 有序集合））和Hash（哈希类型）

```
Redis HyperLogLog：是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。（基数，即不重复元素）
```



### 1.2 Redis分布式锁

• Redis 分布式锁的实现原理
• Redis的并发竞争问题如何解决

**Redis分布式锁实现原理：**

​	具体是通过redis的setNx命令就可以实现。原理就是setNx设值时，只有当值不存在时才能设值成功，所以设值成功的任务才获取了锁，保证同一时刻只有一个任务在执行。另外为了保证不发生死锁，在任务抢到锁之后，再用expire给锁加一个过期时间防止锁忘记了释放。

**Redis并发竞争问题：**

​	当我们有2个甚至多个线程去操作一个redis里的值时，比如我拿到商品的剩余库存要去相减，首先第一个线程拿到的库存是10，减去1，第二个拿到的也是10，也要减一，我们期望的情况下是最后库存是8，但是按照现在这种情况，我们虽然不需要保证执行的顺序性（无论哪个先减都没关系，只要最终能到8就行）,但数据的准确性也没得到保障。

解决方案：

1. 利用redis自带的incr命令，decr命令
2. 可以使用独占锁的方式。（Java代码的话用synchronized或lock，）
3. 用乐观锁的机制，通过WATCH来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。

```
redis事务四大指令: MULTI、EXEC、DISCARD、WATCH：
1.MULTI用来组装一个事务；
2.EXEC用来执行一个事务；
3.DISCARD用来取消一个事务
4.WATCH用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行。
```



### 1.3 Redis持久化

• Redis持久化的几种方式，优缺点是什么，怎么实现的
• Aof和Rdb的优缺点，你在项目中使用的哪一个

**Redis持久化概念：**

Redis是内存数据库，基于内存的操作使它的性能非常之高，但是Redis崩掉的话，会导致数据丢失。为了防止服务宕机时内存数据丢失，Redis提供了持久化功能。持久化就是把内存的数据写到磁盘中去，从而有效避免了因进程退出造成数据丢失的问题。

**Redis持久化原理、方式：**

实现原理：单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。

具体方式：Redis为数据持久化提供了两种方式，RDB（Redis Database，为默认方式）和AOF（Append-only file）。

- RDB：按照规则定时将内存的数据同步到磁盘。
- AOF：将Redis执行的每一条写、删除命令追加到硬盘文件中。

**两种持久化方式比较：**

- aof文件比rdb更新频率高，优先使用aof还原数据。
- aof比rdb更安全也更大
- rdb性能比aof好
- 如果两个都配了优先加载AOF，因为AOF保存的数据更完整

二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些**最终一致性**的意思了。我们项目中用的是默认的Rdb。



### 1.4 Redis缓存失效策略

• Redis的数据淘汰策略

​	通过 **expire**命令和 **persist**命令可以对一个键设定和解除过期时间（过期字典）。然后**针对已经过期的数据，Redis采用定期删除和延迟删除结合的策略。**

- 延迟删除：某个键值过期后，此键值不会马上被删除，而是等到下次被使用的时候，才会被检查到过期，此时才能得到删除。所以延迟删除的缺点很明显：浪费内存。
- 定期删除：每隔一段时间执行一次删除操作。但由于定期检查所有的key是否过期会带来性能问题，因此定期删除策略使用的是`随机抽查`。定时删除从某种程度上也有效地减少了因延迟删除带来的内存浪费。



### 1.5 Redis最大内存置换策略

​	虽然Redis采用了定期删除和延迟删除数据的策略，但随着不断使用，内存占用肯定还是会越来越大。那Redis内存使用达到设置的maxmemory大小，或者耗尽机器最大内存时，Redis就是根据置换策略来处理了。

​	**针对达到最大内存的情况，Redis默认采用的置换策略是直接返回错误，会报Out of Memory，内存溢出错误。**

​	当然我们也可以手动设置修改最大内存策略，打开 redis.conf文件，找到`maxmemory-policy`，在它下面设置即可，redis给我们提供了6种置换策略。

```
# allkeys-lru：回收最近最少使用的键
# volatile-lru：过期字典中回收最近最少使用的键
# allkeys-random：随机回收所有的键
# volatile-random：随机回收过期字典中的键
# volatile-ttl：回收在过期字典的键，并且优先回收存活时间（TTL）较短的键
# noeviction：返回错误
```

使用经验：

- 在所有的 key 都是最近最经常使用，那么就需要选择回收最近最少使用的键，如果你不确定使用哪种策略，那么也用它
- 如果所有的 key 的访问概率都是差不多的，那么可以用随机回收所有的键
- 如果你们都不存在内存不足的情况，那么直接使用默认的策略就好。





### 1.6 Redis缓存穿透/雪崩/击穿

• Redis缓存穿透，缓存雪崩，缓存击穿

**缓存穿透**

        **缓存穿透，是指查询一个数据库一定不存在的数据**。因为查询的数据一定不存在数据库中，所以不会将查询结果放入缓存，导致以后的每次查询都需要去查询数据库，相当于请求直接穿透了缓存到达数据库。假如有恶意攻击，利用这个漏洞，对数据库造成压力，甚至可能压垮数据库。

解决办法：

- 方法一：接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截。
- 方法二（推荐）：从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。
- 方法三：使用布隆过滤器。

**缓存雪崩**

        缓存雪崩，是指在某一个时间段，缓存集中过期失效。如某一批爆款产品的缓存时间设置为一个小时，当一个小时后，这批数据的缓存就集中过期了，而如果此时查询数据量巨大的话，将引起数据库压力过大甚至down机。

解决办法：

- 方法一（推荐）：缓存数据的过期时间添加一个随机数，防止同一时间大量数据过期现象发生。
- 方法二：如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
- 方法三：设置热点数据永远不过期。

**缓存击穿**

        缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

解决办法：

- 方法一：缓存中没有数据，第1个进入的线程，获取锁并从数据库去取数据，没释放锁之前，其他并行进入的线程会等待100ms，再重新去缓存取数据。这样就防止都去数据库重复取数据，重复往缓存中更新数据情况出现。
- 方法二（推荐）：设置热点数据永远不过期。





### 1.7 Redis集群

• redis的主从复制是怎么实现的
• redis集群怎么进行数据分配，hash槽
• Redis缓存分片

**Redis有三种集群方式：主从复制、哨兵模式、Redis-Cluster集群。**（Redis3.0之前只支持单例模式）

#### **1.7.1 主从复制**

**主从复制原理：**

- 从服务器连接主服务器，发送SYNC命令； 


- 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 
- 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 
- 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 
- 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
- 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；（**从服务器初始化完成**）
- 主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。

**主从复制优点：**

- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离
- 为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成
- Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力。
- Master Server是以非阻塞的方式为Slaves提供服务。所以在主从同步期间，客户端仍然可以提交查询或修改请求。
- Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，客户端提交查询请求时，Redis返回同步之前的数据。

**缺点：**

- Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启才能恢复。
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。
- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

#### **1.7.2 哨兵模式**

当主服务器中断服务后，可以将一个从服务器升级为主服务器，以便继续提供服务，但是这个过程需要人工手动来操作。 为此，Redis 2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。

哨兵的作用就是监控Redis系统的运行状况。它的功能包括以下两个。

    **（1）监控主服务器和从服务器是否正常运行。** 
    **（2）主服务器出现故障时自动将从服务器转换为主服务器。**

**哨兵的工作方式：**

- 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
- 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
- 如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态
- 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）
- 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。
- 当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
- 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

 **哨兵模式的优缺点**

**优点：**

- 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
- 主从可以自动切换，系统更健壮，可用性更高。

**缺点：**

- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

#### **1.7.3 Redis-Cluster集群**

**Redis-Cluster概念：**

​	Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis-cluster 会根据节点数量大致均等的将哈希槽映射到不同的节点。这样集群的每个节点负责一部分hash槽。这种结构很容易添加或者删除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；在这一点上，我们以后新增或移除节点的时候不用先停掉所有的 redis 服务。

```
使用单节点时的redis时只有一个表，所有的key都放在这个表里；改用Redis Cluster以后会自动为你生成16384个分区表，你insert数据时会根据上面的简单算法来决定你的key应该存在哪个分区，每个分区里有很多key。
```

**Redis-Cluster特点：**

- 一个Redis Cluster由多个Redis节点构成。不同节点组服务的数据没有交集，也就是每个一节点组对应数据sharding的一个分片。
- 节点组内部分为主备两类节点，对应master和slave节点。两者数据准实时一致，通过异步化的主备复制机制来保证。
- 一个节点组有且只有一个master节点，同时可以有0到多个slave节点，在这个节点组中只有master节点对用户提供写服务，读服务可以由master或者slave提供。


- redis-cluster是基于`gossip协议`实现的无中心化节点的集群，因为去中心化的架构不存在统一的配置中心，各个节点对整个集群状态的认知来自于节点之间的信息交互。
- 在Redis Cluster，这个信息交互是通过Redis Cluster Bus来完成的，所有的redis节点彼此互联(PING-PONG机制)，内部使用`二进制协议`优化传输速度和带宽。


- 客户端与redis节点直连，不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。
- 节点的fail是通过集群中超过半数的节点检测失效时才生效。

```
Gossip protocol（也叫流行病协议）:Gossip 过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。
```

• 分区后，如何将某些相关联的key分配到相同机器？

我们知道，分片其实就是一个hash的过程，对key做hash取模然后划分到不同的机器上。所以在redis中引入了HashTag的概念，可以使得数据分布算法可以根据key的某一个部分进行计算，然后让相关的key落到同一个数据分片。



### 1.8 Redis/Memcache/Mogodb

• redis 和memcache的区别

#### 1.8.1 Memcache

**Memcache概念：**

MemCache的工作流程如下：先检查客户端的请求数据是否在memcached中，如有，直接把请求数据返回，不再对数据库进行任何操作；如果请求的数据不在memcached中，就去查数据库，把从数据库中获取的数据返回给客户端，同时把数据缓存一份到memcached中；每次更新数据库的同时更新memcached中的数据，保证一致性；当分配给memcached内存空间用完之后，会使用LRU（Least Recently Used，最近最少使用）策略加上到期失效策略，失效数据首先被替换，然后再替换掉最近未使用的数据。

```
适用场景：动态系统，做缓存，适合多读少写，大数据量的情况（如人人网大量查询用户信息、好友信息、文章信息等）
```

**Memcache的缺点：**

- 只支持简单的key/value数据结构，不像Redis可以支持丰富的数据类型。
- 无法进行持久化，数据不能备份，只能用于缓存使用，且重启后数据全部丢失。
- 无法进行数据同步，不能将MC中的数据迁移到其他MC实例中。
- MC默认能接受的key的最大长度是250个字符，单个value的大小被限制在1M byte之内，不适合存储较大的数据。

#### 1.8.2 Mongodb

**Mongodb概念：**

​	MongoDB是一个跨平台的，基于分布式文件存储的NoSQL数据库，由C++语言编写的。MongoDB是以文档的形式存储数据，数据结构由键值(key:value)对组成，类似JSON。

   MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。MongoDB的结构中，最小的单位为文档（类似MySQL的行），每一个文档用的是BSON形式来存储（类似JSON），文档的上一层为集合（类似MySQL的表），再上一级为库（类似MySQL的数据库）。

​	Mongodb与Mysql不同的是，mysql的每一次更新操作都会直接写入硬盘，但是mongo不会，做为内存型数据库，数据操作会先写入内存，然后再会持久化到硬盘中去。具体是在mongodb启动时，专门初始化一个线程不断循环（除非应用crash掉），用于在一定时间周期内来从defer队列中获取要持久化的数据并写入到磁盘的journal(日志)和mongofile(数据)处，当进行CUD操作时，记录(Record类型)都被放入到defer队列中以供延时批量（groupcommit）提交写入，默认的时间周期为90s。

Mongodb的优点：

- 更高的写负载，MongoDB拥有更高的插入速度。
  处理很大的规模的单表，当数据表太大的时候可以很容易的分割表，添加1个新字段不会对旧表格有任何影响，整个过程会非常快速。
- 高可用性，设置M-S不仅方便而且很快，MongoDB还可以快速、安全及自动化的实现节点（数据中心）故障转移。
- 查询效率高，MongoDB支持二维空间索引，比如管道，因此可以快速及精确的从指定位置获取数据。MongoDB在启动后会将数据库中的数据以文件映射的方式加载到内存中。如果内存资源相当丰富的话，这将极大地提高数据库的查询速度。
- 支持持久化，Mongodb做为内存型数据库，数据操作会先写入内存，然后再会持久化到硬盘中去。

**Mongodb的缺点：**

- 不支持事务。
- MongoDB占用内存过大 。
- MongoDB没有成熟的维护工具。



### 1.9 Redis应用

• redis模拟session，除了redis你还考虑过别的吗

1. **缓存**

   redisTemplate

2. **分布式锁**

   setNx

3. **计数器**

   诸如统计点击数等应用。由于单线程，可以避免并发问题，保证不会出错，而且100%毫秒级性能！爽。（INCRBY）

4. **排行榜**

   谁得分高谁排名往上。命令：ZADD（有续集，sorted set）

## 2.MQ

### 2.1 消息队列概念/作用

• MQ的作用，同步转异步，消除峰值

#### **2.1.1 什么是消息队列**

​	队列是一种先进先出的数据结构，消息队列可以简单理解为：把要传输的数据放在队列中。

​	消息队列可以看做是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。然后把数据放到消息队列叫做生产者，从消息队列里边取数据叫做消费者。生产者只管把消息发布到 MQ 中而不用管谁来取，消费者只管从 MQ 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在。

#### **2.1.2 消息队列的作用**

**1. 解耦**

​	比如系统A的数据，放到消息队列后，系统B和系统C从消息队列中拿数据，这样系统A与系统B、C都解耦了。

**2. 异步**

​	比如系统A运算出某个数据需要50ms，然后调用系统B的接口需要300ms，调用系统C的接口需要300ms。那么这次请求就需要50+300+300=650ms。为了提高用户体验和吞吐量，其实可以异步地调用系统B、C的接口。我们可以等系统A执行完了以后，将数据写到消息队列中，然后就直接返回了，至于其他的操作，则异步处理，就是将调用其他系统接口异步化，这样从请求到返回只需要100ms了（异步）

**3. 削峰/限流**

​	比如现在我们每个月要搞一次大促，大促期间的并发可能会很高的，比如每秒3000个请求。假设我们现在有两台机器处理请求，并且每台机器只能每次处理1000个请求。那多出来的1000个请求，可能就把我们整个系统给搞崩了…所以，有一种办法，我们可以写到消息队列中。系统B和系统C根据自己的能够处理的请求数去消息队列中拿数据，这样即便有每秒有8000个请求，那只是把请求放在消息队列中，去拿消息队列的消息由系统自己去控制，这样就不会把整个系统给搞崩。

**4. 日志处理** 

​	解决大量日志传输。

**5. 消息通讯** 

​	消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。

**缺点：**

- 系统复杂性增加：加了消息队列，需要保证消息不会重复消费，需要保证消息的可靠性，需要保证消息队列的高可用
- 系统的可用性降低：如果消息队列挂了，那么系统也会受到影响



#### 2.1.3 常见的消息队列

• ActiveMQ、RabbitMQ、Kafka、RocketMQ、ZeroMQ ...


**消息队列如何选型？**

（1）中小型软件公司，建议选RabbitMQ.一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。正所谓，成也萧何，败也萧何！他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。

（2）大型软件公司，根据具体使用在rocketMq和kafka之间二选一。一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。至于kafka，如果是**大数据领域**的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。具体该选哪个，看使用场景。

![img](https://img-blog.csdn.net/20170816171523564?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvb01hdmVyaWNrMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



Kafka/RabMQ区别

- RabbitMq比kafka成熟，在可用性上，稳定性上，可靠性上，RabbitMq超过kafka。

- Kafka的性能（吞吐量、tps）比RabbitMq要强

- Kafka设计的初衷就是处理日志，可看做是一个日志系统，针对性很强，所以它并没有具备一个成熟MQ应该具备的特性

- 实际生产应用中，通常会使用kafka作为消息传输的数据管道，rabbitmq作为交易数据作为数据传输管道

- Rabbitmq在金融场景中经常使用，具有较高的严谨性，数据丢失的可能性更小，同事具备更高的实时性；而kafka优势主要体现在吞吐量上，虽然可以通过策略实现数据不丢失，但从严谨性角度来讲，大不如rabbitmq；

- Rabbitmq不支持动态扩容，Kafka通过Zookeeper可以实现动态扩容。

- RabbitMQ天然支持集群，而Kafka还要借助ZooKeeper分别来实现HA方案和保存集群的元数据。

  



### **2.2 消息队列的问题**

#### **2.2.1. 如何实现高可用？**

​	无论是我们使用消息队列来做解耦、异步还是削峰，消息队列肯定不能是单机的。试着想一下，如果是单机的消息队列，万一这台机器挂了，那我们整个系统几乎就是不可用了。所以，当我们项目中使用消息队列，都是得集群/分布式的。要做集群/分布式就必然希望该消息队列能够提供现成的支持，而不是自己写代码手动去实现。

> 回答要点：使用消息队列的集群模式，
>
> - 如RocketMQ，他的集群就有多master模式、多master多slave异步复制模式、多master多slave同步双写模式。多master多slave。
> - 再如RabbitMQ，它的集群也有普通集群和镜像集群。
> - 再如Kafka集群中包含若干Producer，若干broker，若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。

#### **2.2.2. 处理数据丢失问题？**

​	我们将数据写到消息队列上，系统B和C还没来得及取消息队列的数据，就挂掉了。如果没有做任何的措施，我们的数据就丢了。学过Redis的都知道，Redis可以将数据持久化磁盘上，万一Redis挂了，还能从磁盘从将数据恢复过来。同样地，消息队列中的数据也需要存在别的地方，这样才尽可能减少数据的丢失。那存磁盘？数据库？Redis？分布式文件系统？同步存储还是异步存储？

> 回答：其实这个可靠性传输，每种MQ都要从三个角度来分析：
>
> - 生产者弄丢数据
> - 消息队列弄丢数据
> - 消费者弄丢数据
>
> （1）生产者丢数据
> ​        从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。
> transaction机制就是说，发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。
> ​        然而，这种方式有个缺点：吞吐量下降。因为，按照经验，生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了。如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。处理Ack和Nack的代码如下所示： channel.addConfirmListener(new ConfirmListener() { handleNack(){...}  handleAck(){...}});  
>
> （2）消息队列丢数据
> ​        处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。
> ​       RabMQ持久化: 持久化exchange（durable）、持久化Quene（durable）、持久化Message（deliver_mode=2）
>
> （3）消费者丢数据
> ​        消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rabbitMQ会立即将消息删除，这种情况下，如果消费者出现异常而未能处理消息，就会丢失该消息。
> ​        至于解决方案，采用手动确认消息即可。

#### **2.2.3.获取消息队列数据？**

消费者怎么从消息队列里边得到数据？有两种办法：

- 生产者将数据放到消息队列中，消息队列有数据了，主动叫消费者去拿（俗称push）
- 消费者不断去轮训消息队列，看看有没有新的数据，如果有就消费（俗称pull）

#### **2.2.4. 消息重复消费问题？ **

​	**造成消息重复的根本原因是：网络不可达**。所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？

> 要点：重复消费时也要保证幂等性
>
> 这个问题针对业务场景来答，分以下三种情况：
>
> （1）比如，你拿到这个消息做数据库的insert操作，那就容易了，给这个消息做一个唯一的主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
>
> （2）再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。
>
> （3）如果上面两种情况还不行，上大招。准备一个第三方介质，来做消费记录。以redis为例，记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在redis中了，那么就不再处理这条消息。

#### **2.2.5. 保证消息绝对顺序？**

​	比如你在 mysql 里增改删一条数据，对应出来了增删改 3 条 `binlog` 日志，接着这三条 `binlog` 发送到 MQ 里面，再消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。本来这个数据同步过来，应该最后这个数据被删除了；如果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。

> RabbitMQ错乱的场景：一个 queue，多个 consumer。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。
>
> RabbiMQ的解决方案：将需要保持先后顺序的消息放到同一个消息队列中，然后只用一个消费者去消费该队列。然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。
>
> kafka的解决方案：方法1：一个topic，一个partition，一个consumer，内部单线程消费。方法2：写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。
>
> 
>
> 总之，针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。

#### **2.2.6. 消息积压/过期失效？**

​	如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时呢？

​	这问法本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？

​	所以就这事儿，其实线上挺常见的，一般不出，一出就是大 case。一般常见于，举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。

**2.2.6.1 大量消息在 mq 里积压了几个小时了还没解决**

​	几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。

​	一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。

​	一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：

- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
- 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
- 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
- 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。

**2.2.6.2 mq 中的消息过期失效了**

假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是**大量的数据会直接搞丢**。

这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是**批量重导**，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。

假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。

**2.2.6.3 mq 都快写满了**

如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，**消费一个丢弃一个，都不要了**，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

#### **2.2.7. 设计消息队列架构？**

其实聊到这个问题，一般面试官要考察两块：

- 你有没有对某一个消息队列做过较为深入的原理的了解，或者从整体了解把握住一个消息队列的架构原理。
- 看看你的设计能力，给你一个常见的系统，就是消息队列系统，看看你能不能从全局把握一下整体架构设计，给出一些关键点出来。

说实话，问类似问题的时候，大部分人基本都会蒙，因为平时从来没有思考过类似的问题，大多数人就是平时埋头用，从来不去思考背后的一些东西。类似的问题，比如，如果让你来设计一个 Spring 框架你会怎么做？如果让你来设计一个 Dubbo 框架你会怎么做？如果让你来设计一个 MyBatis 框架你会怎么做？

其实回答这类问题，说白了，不求你看过那技术的源码，起码你要大概知道那个技术的基本原理、核心组成部分、基本架构构成，然后参照一些开源的技术把一个系统设计出来的思路说一下就好。

比如说这个消息队列系统，我们从以下几个角度来考虑一下：

- 首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？
- 其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。
- 其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。
- 能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。

mq 肯定是很复杂的，面试官问你这个问题，其实是个开放题，他就是看看你有没有从架构角度整体构思和设计的思维以及能力。确实这个问题可以刷掉一大批人，因为大部分人平时不思考这些东西。



### 2.3 JMS

**JMS概念**

        JMS（Java MessageService）即 Java消息服务应用程序接口，是 Java 平台中关于面向消息中间件的API，也是Java平台上有关面向消息中间件(MOM)的技术规范。用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java消息服务是一个与具体平台无关的API，绝大多数MOM提供商都对JMS提供支持。从使用角度看，JMS和JDBC担任差不多的角色，用户都是根据相应的接口可以和实现了JMS的服务进行通信，进行相关的操作。

**JMS角色**

- JMS provider：实现了JMS接口的消息中间件，如ActiveMQ，RabbitMQ以及Redis
- JMS client：生产或者消费消息的应用
- JMS producer/publisher：JMS消息生产者
- JMS consumer/subscriber：JMS消息消费者
- JMS message：消息，在各个JMS client传输的对象；
- JMS queue：Provider存放等待被消费的消息的地方
- JMS topic：一种提供多个订阅者消费消息的一种机制；在MQ中常常被提到，topic模式。

**JMS两种消息模型**

1. **点对点模型**（peer-2-peer）：当采用点对点模型时，消息将发送到一个队列，该队列的消息只能被一个消费者消费。
2. **发布订阅模型**（publish-subscribe）：采用发布订阅模型时，消息可以被多个消费者消费。该模型下生产者和消费者完全独立，不需要感知对方的存在。

**JMS消息路由**

​	消息如何从producer端达到consumer端由`消息路由（message-routing）`来决定。在JMS中，消息路由非常简单，由producer和consumer链接到同一个queue（p2p）或者topic（pub/sub）来实现消息的路由。JMSconsumer同时支持message selector（消息选择器），通过消息选择器，consumer可以只消费那些通过了selector筛选的消息。



### 2.4 AMQP

**AMQP概念**

​	AMQP（Advanced Message Queuing Protocol：高级消息队列协议），是应用层为面向消息的中间件设计的协议。而JMS 只是一组技术规范（API），这是他们的本质区别。AMQP不从API层进行限定，而是直接定义网络交换的数据格式。这使得实现了AMQP的provider天然性就是跨平台的。意味着我们可以使用Java的AMQP provider，同时使用一个python的producer加一个rubby的consumer。从这一点看，AQMP可以用http来进行类比，不关心实现的语言，只要大家都按照相应的数据格式去发送报文请求，不同语言的client均可以和不同语言的server链接。

**AMQP五种消息模型**

​	在AMQP中，`消息路由（messagerouting）`和JMS存在一些差别，在AMQP中增加了`交换机（Exchange）`和`binding`的角色。producer将消息发送给Exchange，binding决定Exchange的消息应该发送到那个queue，而consumer直接从queue中消费消息。queue和exchange的bind有consumer来决定。AMQP的routing scheme图示过程下图如下。

![img](https://img-blog.csdnimg.cn/20191120105119363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRfSW5fSmF2YQ==,size_16,color_FFFFFF,t_70)

```
• Producer将消息发送给Exchange时会带一个路由键（Routing-key）；
• Binding决定Exchange的消息应该发送到那个queue，一般有一个绑定键（Binding-key）；通过路由键-绑定键可以确定消息该发送给那个Quene。
• 每个Broker都能创建很多vhost，我们称之为虚拟主机，每个虚拟主机其实都是mini版的Broker，拥有自己的队列，交换器和绑定，拥有自己的权限机制。
```

**交换机类型有如下几种：**

1. **直连交换机**（direct exchange）：

   需要将一个队列绑定到交换机上，要求该消息与一个特定的路由键完全匹配。

2. **主题交换机**（topic change）：

   需要将队列需要绑定要一个模式上。符号“#”匹配一个或多个词，符号“*”匹配不多不少一个词。

3. **广播交换机**（fanout exchange）：

   只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。（广播）

4. 头交换机（headers exchange）：

   headers与direct的模式不同，不是使用routingkey去做绑定。而是通过消息headers的键值对匹配。消息header数据里有一个特殊值”x-match”，它有两个值：all/any。all: 默认值。一个传送消息的header里的键值对和交换机的header键值对全部匹配，才可以路由到对应交换机；any: 一个传送消息的header里的键值对和交换机的header键值对任意一个匹配，就可以路由到对应交换机。

5. 系统交换机（system exchange）：

   系统使用的交换机，可以不用管。

   

### 2.5 RabbitMQ

#### **2.5.1 RabMQ概念**

​	RabbitMQ是一个面向消息的中间件。它实现了高级消息队列协议（AMQP）。它的服务器端用Erlang语言编写，支持多种客户端，如：Python、Ruby、Java等，支持AJAX。用于在分布式系统中存储转发消息，支持消息的持久化，并具有高可用、高并发的特点。它有几个比较重要的概念：

- Producer：生产者，负责生产消息。
- Exchange：交换机，负责将消息路由到一个或多个Queue中（或者丢弃），有直连、主题、广播、首部四种类型。
- Quene：队列，负责存储消息。
- Vhost：虚拟主机，交换机和队列合起来就称为虚拟主机。不同虚拟主机下的资源互不可见。相当于一个package。
- Broker：主机，多个虚拟主机合起来就称为主机。
- Binding：绑定，负责将Exchange与Queue关联起来。
- Routing-Key/Binding-Key：路由键/绑定键，负责让交换机把消息路由到正确的Queue中。
- Consumer：消费者，负责消费消息。
- acknowledgment：消息回执，负责消费者在消费完消息后发送给RabbitMQ，以确认删除该消息。

```
项目中引入：amqp包
原生api中：用channel的basicPublish生成数据，用queueDeclare/handleDelivery/basicConsume 来关注/处理/回复队列
springboot中：converAndSend()生成数据，消费端通过receiveAndConvert接收（@RabbitListener、@RabbitHandler）。
```

#### **2.5.2 RabMQ优点**

1. 可靠性，RabbitMQ的持久化支持，保证了消息的稳定性；
2. 高并发，RabbitMQ使用了Erlang开发语言，Erlang是为电话交换机开发的语言，天生自带高并发光环和高可用特性；
3. 集群部署简单，正是应为Erlang使得RabbitMQ集群部署变的超级简单；
4. 跨平台，RabbitMQ实现了AMQP标准，意味它支持多种语言拿到producer和consumer；
5. 社区活跃度高，根据网上资料来看，RabbitMQ也是首选；

缺点：

1. **不支持动态扩容**

#### 2.5.3 RabMQ不丢数据

**RabMQ发送确认**

生产者发送消息, 先发送消息到Exchange, 然后Exchange再路由到Queue, 这中间就需要确认两个事情

- 确认消息是否成功发送到Exchange：

  ​	方式1：通过AMQP的事务机制：chanel.txSelect() 声明启动事务模式，通过txComment()提交事务，txRollback() 回滚事务，但这种方式过于重量级导致性能不高，一般不用，

  ​	方式2：使用confirm确认机制：实现`ConfirmCallback`并重写confirm回调方法，消息发送到Broker后触发回调。

- 确认消息是否从Exchange成功路由到Queue

  ​	实现`ReturnCallback`并重写returnedMessage回调方法, 可以确认消息从EXchange路由到Queue失败, 注意: 这里的回调是一个失败回调, 只有消息从Exchange路由到Queue失败才会回调这个方法


```java
 channel.addConfirmListener(new ConfirmListener() { handleNack(){"已丢失"}  handleAck(){"未丢失"}});
```

**RabMQ接收确认**

​	为了保证数据不被丢失，RabbitMQ支持消息确认机制，即acknowledgments。Consumer在收到并处理数据后，会给RabbitMQ发送一个ack，就是告诉RabbitMQ数据已经被接收，处理完成，RabbitMQ可以去安全的删除它了。

​	如果Consumer退出了但是没有发送ack，那么RabbitMQ就会把这个Message发送到下一个Consumer。这样就保证了在Consumer异常退出的情况下数据也不会丢失。

```
消息确认模式有：
  - AcknowledgeMode.NONE：自动确认（默认，有丢失的可能）
  - AcknowledgeMode.AUTO：根据情况确认
  - AcknowledgeMode.MANUAL：手动确认
消息确认模式的确认方式
  - 普通确认:waitForConfirms
  - 批量确认:waitForConfirms
  - 异步确认:addConfirmListener
通过@RabbitListener、@RabbitHandler定义接收方法，接收方法中：	
  -channel.basicAck(...);	//确认接收
  -channel.basicNack(...);	//否认接收
```

```
Prefetch count
前面我们讲到如果有多个消费者同时订阅同一个Queue中的消息，Queue中的消息会被平摊给多个消费者。这时如果每个消息的处理时间不同，就有可能会导致某些消费者一直在忙，而另外一些消费者很快就处理完手头工作并一直空闲的情况。我们可以通过设置prefetchCount来限制Queue每次发送给每个消费者的消息数，比如我们设置prefetchCount=1，则Queue每次给每个消费者发送一条消息；消费者处理完这条消息后Queue会再给该消费者发送一条消息。
```

​	至于重复消费时：注意幂等性即可。根据业务场景处理。

#### 2.5.4 RabMQ数据持久化

​	RabbitMQ是通过`数据持久化`保证消息可靠性，为了保证RabbitMQ在退出或者crash等异常情况下数据没有丢失，需要将queue，exchange和Message都持久化。虽然持久化会造成性能损耗，但为了生产环境的数据一致性，这是我们必须做出的选择。但我们可以通过设置消息过期时间、降低发送消息大小等其他方式来尽可能的降低MQ性能的降低。

- exchange持久化，在声明时指定durable => true
- queue持久化，在声明时指定durable => true
- 消息持久化，在投递时指定delivery_mode=> 2（1是非持久化）

```
• 如果exchange和queue都是持久化的，那么它们之间的binding也是持久化的。如果exchange和queue两者之间有一个持久化，一个非持久化，就不允许建立绑定。
• 注意：一旦创建了队列和交换机，就不能修改其标志了。例如，如果创建了一个non-durable的队列，然后想把它改变成durable的，唯一的办法就是删除这个队列然后重现创建。
• Rabbit会将你的持久化消息写入磁盘上的持久化日志文件，等消息被消费之后，Rabbit会把这条消息标识为等待垃圾回收。缺点也很明显，那就是性能会下降。
```

**交换机持久化（exchange）**

```java
public TopicExchange(String name, boolean durable, boolean autoDelete, Map<String, Object> arguments)
参数说明：
• durable：是否持久化
```

 **队列持久化（Quene）**

```java
Queue(String name, boolean durable, boolean exclusive, boolean autoDelete,Map<String, Object> arguments)
参数说明：
• durable：是否持久化
• exclusive：排他队列，如果一个队列被声明为排他队列，该队列仅对首次申明它的连接可见，并在连接断开时自动删除。这里需要注意三点：1. 排他队列是基于连接可见的，同一连接的不同信道是可以同时访问同一连接创建的排他队列；2.“首次”，如果一个连接已经声明了一个排他队列，其他连接是不允许建立同名的排他队列的，这个与普通队列不同；3.即使该队列是持久化的，一旦连接关闭或者客户端退出，该排他队列都会被自动删除的，这种队列适用于一个向客户端发送读取消息的应用场景。
• autoDelete：自动删除，若该队列没有任何订阅的消费者，服务断开时队列会被自动删除。这种队列适用于临时队列。
```

**消息持久化（Message）**

```
消息默认是持久化的。因为 DEFAULT_DELIVERY_MODE = MessageDeliveryMode.PERSISTENT;
```

#### 2.5.5 RabMQ集群

​	出于MQ中间件本身的可靠性、并发性、吞吐量和消息堆积能力等问题的考虑，在生产环境上一般都会考虑使用RabbitMQ的集群方案。RabbitMQ的集群模式有两种：**普通模式**和**镜像模式**。普通模式为默认的集群模式。镜像模式即把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案

**普通模式：**

​	默认模式，以两个节点（A、B）为例来进行说明。对于Queue来说，消息实体只存在于其中一个节点A或者B，A和B两个节点仅有相同的元数据，即队列的结构。当消息进入A节点的Queue后，consumer从B节点消费时，RabbitMQ会临时在A、B间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应平均连接每一个节点，从中取消息。该模式存在一个问题就是当A节点故障后，B节点无法取到A节点中还未消费的消息实体。如果做了队列持久化或消息持久化，那么得等A节点恢复，然后才可被消费，并且在A节点恢复之前其它节点不能再创建A节点已经创建过的持久队列；如果没有持久化的话，消息就会失丢。这种模式更适合非持久化队列，只有该队列是非持久的，客户端才能重新连接到集群里的其他节点，并重新创建队列。假如该队列是持久化的，那么唯一办法是将故障节点恢复起来。

**镜像模式：**

​	该模式下，会把需要的队列做成镜像队列，存在与多个节点中。属于RabbitMQ的HA方案。该模式和普通模式不同之处在于，**消息实体会主动在镜像节点间同步**，而不是在客户端取数据时临时拉取。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。所以在对可靠性要求较高的场合中适用。

#### **2.5.6 RabMQ负载均衡**

​	我们虽然前面已经创建了集群，但是我们在之前连接集群的方式，都是直连集群中的某一个几点，这样被直连的几点将会承受很大的压力，剩余的节点则比较浪费，所谓的负载均衡就是可以将我们的请求按照一定规则打散到集群中的各个节点，这样我们才可能尽可能大的发挥出系统的性能，提高系统的吞吐量。

​	对RabbitMQ集群使用软件负载均衡技术，目前主流的方式有在**客户端内部实现负载均衡**，或者使用**HAProxy**、**LVS**等负载均衡软件来实现。

​	客户端内部实现负载均衡，即在客户端连接时简单的使用负载均衡算法来实现负载均衡。可以使用轮询法、或随机法等方式获取到RabbitMQ集群的某个节点ip。

​	HAProxy（Hign Available Proxy 高可用代理）提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。根据官方数据，其最高极限支持10G的并发。HAProxy支持从4层至7层的网络交换，即覆盖所有的TCP协议。就是说，Haproxy 甚至还支持 Mysql 的均衡负载。

​	LVS（Linux Virtual Server Linux虚拟服务器）配合Keepalived一起使用同样可以实现高可靠的负载均衡，LVS不需要额外的配置文件，直接集成在Keepalived的配置文件之中。

```java
//客户端内部实现负载均衡代码如下：
public class RoundRobin {
    private static List<String> list = new ArrayList<String>(){{
        add("192.168.0.2");
        add("192.168.0.3");
        add("192.168.0.4");
    }};
    private static int pos = 0;
    private static final Object lock = new Object();
    public static String getConnectionAddress(){
        String ip = null;
        synchronized (lock) {
            ip = list.get(pos);
            if (++pos >= list.size()) {
                pos = 0;
            }
        }
        return ip;
    }
}
```

#### 2.5.7 Rab使用实例

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191105115629752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hlbGxvZ2JhYnk=,size_16,color_FFFFFF,t_70)

开发步骤：

1.引入rabbitmq包：

```xml
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

2.配置rabbitmq连接信息：

```properties
spring:
  rabbitmq:
    host: 47.112.xx.xx
    port: 5672
    username: admin
    password: 123456
    #rbbitmq虚拟主机路径,其它主机需配置权限
    virtual-host: /
    listener:
      simple:
        acknowledge-mode: manual #手动接受数据
        #max-concurrency: 10 #最大并发
        #prefetch: 1 #限流
```

3.开启rabbitmq

```java

@EnableRabbit /**开启rabbitmq*/

//消息转换器MessageConverter: MessageConverter有两方面的功能，除了把Java对象转换成对应的Jms Message之外还可以把Jms Message转换成对应的Java对象。
/**消息的转换器
  * 设置成json 并放入到Spring中
* */
@Bean
public MessageConverter messageConverter(){
    return new Jackson2JsonMessageConverter();
}
```

4.配置rabbit的交换机、路由、队列绑定关系

```java
@Configuration
public class RabbitConfig {

    //队列 起名：TestDirectQueue
    @Bean
    public Queue TestDirectQueue() {
        return new Queue("TestDirectQueue",true);  //true 是否持久
    }

    //Direct交换机 起名：TestDirectExchange
    @Bean
    DirectExchange TestDirectExchange() {
        return new DirectExchange("TestDirectExchange");
    }

    //绑定  将队列和交换机绑定, 并设置用于匹配键：TestDirectRouting
    @Bean
    Binding bindingDirect() {
        return BindingBuilder.bind(TestDirectQueue()).to(TestDirectExchange()).with("TestDirectRouting");
    }
}
```

5.服务端开发推送接口

```java
	@Autowired
    private RabbitTemplate rabbitTemplate;

    @RequestMapping("push")
    public Object push(String msg){
        String messageId = String.valueOf(UUID.randomUUID());
        String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"));
        Map<String,Object> map=new HashMap<>();
        map.put("messageId",messageId);
        map.put("messageData",msg);
        map.put("createTime",createTime);
        //将消息携带绑定键值：TestDirectRouting 发送到交换机TestDirectExchange
        rabbitTemplate.convertAndSend("TestDirectExchange", "TestDirectRouting", map);
        return ResponseMessage.ok( "推送成功!");
    }
```

6.消费端监听端口

```java
@Component
@RabbitListener(queues = "TestDirectQueue")//监听的队列名称 TestDirectQueue
public class DirectReceiver {
 
    @RabbitHandler
    public void process(Map testMessage) {
        System.out.println("-----------------------");
        System.out.println("DirectReceiver消费者收到消息  : " + testMessage.toString());
        System.out.println("-----------------------");
    }
 
}
```



### 2.6 Kafka

#### 2.6.1 Kafka概念

​	Kafka是一个分布式发布订阅消息系统。由Scala和Java语言编写。据说Kafka设计的初衷就是处理日志，设计目标就是高吞吐量，所以kafka自己仿照AMQP设计了一套高性能但是不通用的协议。所以高水平扩展和高吞吐量是Kafka的特点，可看做是一个日志系统，针对性很强，所以它并没有具备一个成熟MQ应该具备的特性。

![kafka架构](https://img-blog.csdnimg.cn/20191121154546823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0hlbGxvV29ybGRfSW5fSmF2YQ==,size_16,color_FFFFFF,t_70)



Kafka有几个比较重要的基本概念：

- Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker。
- Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。
- Partition：Partition是物理上的概念，每个Topic包含一个或多个Partition。
- Producer：负责发布消息到Kafka broker。将消息发布到它指定的topic中，并负责决定发布到哪个分区。
- Consumer：消息消费者，向Kafka broker读取消息的客户端。
- Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。
- Leader：每个partition有多个副本，其中有且仅有一个作为Leader，Leader是当前负责数据的读写的partition。
- Follower：Follower跟随Leader，所有写请求都通过Leader路由，数据变更会广播给所有Follower，Follower与Leader保持数据同步。如果Leader失效，则从Follower中选举出一个新的Leader。当Follower与Leader挂掉、卡住或者同步太慢，leader会把这个follower从“in sync replicas”（ISR）列表中删除，重新创建一个Follower。


```
即1个Kafka集群 -> 多个服务器Broker
	1个Broker -> 1~n个主题topic
		1个topic -> 1~n个分区Partition
			1个partition -> 通过n个segment文件存储数据
			1个partition -> n个副本，有1个Leader，n-1个Follower，Leader是当前负责数据的读写的partition。
```

**基础概念的相关内容：**

- 生产者将消息发布到broker的topic中，topic中的数据又分割为一个或多个partition。所以消息最终是存储到一个partition中，生产者也可以指定数据存储的partition。每个partition通过n个segment文件存储数据。任何发布到此 Partition 的消息都会被追加到 Log 文件的尾部，在分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，也就是我们的 Offset。Offset 是一个 Long 型的数字。我们通过这个 Offset 可以确定一条在该 Partition 下的唯一消息。

  ```
  - 如果没有 Key 值则进行轮询发送。
  - 如果有 Key 值，对 Key 值进行 Hash，然后对分区数量取余，保证了同一个 Key 值的会被路由到同一个分区;如果想队列的强顺序一致性，可以让所有的消息都设置为同一个 Key。
  ```


- partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。
- 如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。


- 通过分区的概念，Kafka可以在多个consumer组并发的情况下提供较好的有序性和负载均衡。将每个分区分只分发给一个consumer组，这样一个分区就只被这个组的一个consumer消费，就可以顺序的消费这个分区的消息。因为有多个分区，依然可以在多个consumer组之间进行负载均衡。注意consumer组的数量不能多于分区的数量，也就是有多少分区就允许多少并发消费。Kafka只能保证一个分区之内消息的有序性，在不同的分区之间是不可以的，这已经可以满足大部分应用的需求。如果需要topic中所有消息的有序性，那就只能让这个topic只有一个分区，当然也就只有一个consumer组消费它。


- Kafka采用拉取模型（pull），由Consumer记录消费状态，每个Consumer互相独立并顺序读取每个Partition的消息。每个Topic允许被多个Consumer Group消费，每个Consumer Group包括多个Consumer实例，不同Consumer Group之间互相独立，消费相同数据。

- Producer生产的消息会保存在Kafka集群中，不管消息有没有被消费，用户可以通过设置`保留时长`来清理过期的数据。

  

#### 2.6.2 Kafka优缺点 

**优点：**

- 快速持久化：通过磁盘顺序读写与零拷贝机制，可以在O(1)的系统开销下进行消息持久化；
- 高吞吐：在一台普通的服务器上既可以达到10W/s的吞吐速率；
- 高堆积：支持topic下消费者较长时间离线，消息堆积量大；
- 完全的分布式系统：Broker、Producer、Consumer都原生自动支持分布式，依赖zookeeper自动实现负载均衡；
- 支持Hadoop数据并行加载：对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。
- 对cpu和内存、网络开销消耗较小

**缺点：**

1. 复杂性。Kafka需要Zookeeper的支持

2. 重复消息。Kafka保证每条消息至少送达一次，虽然几率很小，但一条消息可能被送达多次。

   

**为什么Kafka 的写入操作是很快的？**

　　主要得益于它对磁盘的使用方法的不同 虽然Kafka 会持久化所有数据到磁盘，但本质上每次写入操作其实都只是把数据写入到操作系统的页缓存中，然后由操作系统自行决定什么时候把页缓存中的数据写回磁盘上。这样的设计有几个主要优势：

1. 操作系统页缓存是在内存中分配的，所以消息写入的速度非常快。

2. Kafka 不必直接与底层的文件系统打交道。所有烦琐的 1/0 操作都交由操作系统来处理。
3. Kafka 写入操作采用追加写入（ append ）的方式，避免了磁盘随机写操作。
4. 使用以 sendfile 为代表的零拷贝技术加强网络间的数据传输效率。

```
• 传统的读取是：磁盘 -> 页面缓存 -> 用户空间缓冲区 -> socket缓冲区 -> 网卡接口，即需要复制4次。
• “零拷贝技术”只用将磁盘文件的数据复制到页面缓存中一次，然后将数据从页面缓存直接发送到网络中（发送给不同的订阅者时，都可以使用同一个页面缓存），避免了重复复制操作。比如有10个消费者，传统方式下，数据复制次数为4*10=40次，而使用“零拷贝技术”只需要1+10=11次，一次为从磁盘复制到页面缓存，10次表示10个消费者各自读取一次页面缓存。
• DMA，全称叫Direct Memory Access，一种可让某些硬件子系统去直接访问系统主内存。因为有了DMA，才可以直接
• 在Java中的零拷贝实现是在FileChannel中，其中有个方法transferTo(position,fsize,src)
```

#### 2.6.3 Kafka不丢数据

**Kafka发送确认**

kafka的**ack机制**：在kafka发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常的能够被收到，其中状态有0，1，-1。

- 如果是同步的方式（同步），ack机制能够保证数据的不丢失。，如果ack设置为0，风险很大，一般不建议设置为0。即使设置为1，也会随着leader宕机丢失数据。
- 如果是**异步模式**：也会考虑ack的状态，除此之外，异步模式下的有个buffer，通过buffer来进行控制数据的发送，有两个值来进行控制，时间阈值与消息的数量阈值，如果buffer满了数据还没有发送出去，有个选项是配置是否立即清空buffer。可以设置为-1，永久阻塞，也就数据不再生产。**异步模式下**，即使设置为-1。也可能因为程序员的不科学操作，操作数据丢失，比如kill -9，但这是特别的例外情况。

**结论：producer有丢数据的可能，但是可以通过配置保证消息的不丢失。**

producer有丢数据的可能，但是可以通过配置保证消息的不丢失。通过kafka的ack机制，可以在kafka发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常的能够被收到。

```
producer.type=sync
  sync/async：同步/异步
request.required.acks=1
  0: producer不会等待broker发送ack，消息可靠性最低，但是延迟、吞吐最高
  1: 当leader接收到消息之后发送ack，这样会有更好的可靠性，但是会降低一部分吞吐。
 -1: 当所有的follower都同步消息成功后发送ack，这样可靠性最高，吞吐最低。
queue.enqueue.timeout.ms = -1
 -1: 无阻塞超时限制,消息不会被抛弃 
  0: 立即清空队列,消息被抛弃 
```

```java
//异步发送消息
ProducerRecord<String, String> rec = new ProducerRecord<String, String>("test-topic","hello world");
producer.send(rec,new Callback() {
    public void onCompletion(RecordMetadata metadata,Exception exception) {
        System.out.println("ack!!!");
    }
}); //在发送消息后，收到回执确认。
```



**Kafka接收确认**

**可以通过设置手动提交offset，保证数据的不会丢失。**



**所以产生数据丢失的两种情况：**

- 同步模式：在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失。
- 异步模式：当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉。

只要能避免上述两种情况，那么就可以保证消息不会被丢失。

- 确认（ACK）机制设置为-1，也就是让消息写入leader和所有的ISR副本。
- 还有，在异步模式下，如果消息发出去了，但还没有收到确认的时候，缓冲池满了，在配置文件中设置成不限制阻塞超时的时间，也就说让生产端一直阻塞，这样也能保证数据不会丢失。

**所以消费数据丢失的情况：**

kafka提供了两套consumer API：高级Consumer API和低级API（strom-kafka）。

高级API在kafka拉取到数据之后就直接提交offset下标。可能提交了offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“诡异”的消失了，导致数据丢失；

解决办法：

- 如果使用了高级API，关闭自动提交位移 enable.auto.commit=false ，确认数据被完成处理之后，再更新offset值。
- 如果使用了低级API（strom-kafka），要开启storm的ackfail机制。手动控制offset值。



#### 2.6.4 Kafka持久化

Kafka是要持久化消息的，而且要把消息持久化到磁盘上。这样做的好处如下。

- 解耦消息发送与消息消费：本质上来说， Kafka 最核心的功能就是提供了生产者－消费者模式的完整解决方案。通过将消息持久化使得生产者方不再需要直接和消费者方藕合，它只是简单地把消息生产出来井交由 Kafka 服务器保存即可，因此提升了整体的吞吐量。

- 实现灵活的消息处理：很 Kafka 的下游子系统（接收 Kafka 消息的系统）都有这样的需求一一对于已经处理过的消息可能在未来的某个时间点重新处理 次，即所谓的消息重演（ message replay ）。消息持久化便可以很方便地实现这样的需求。
- 另外， Kafka 实现持久化的设计也有新颖之处。普通的系统在实现持久化时可能会先尽量使用内存，当内存资源耗尽时，再次性地把数据“刷盘”；而 Kafka 则反其道而行之，所有数据都会立即被写入文件系统的持久化日志中，之后 Kafka 服务器才会返回结果给客户端通知它们消息已被成功写入。这样做既实时保存了数据，又减少了 Kafka 程序对于内存的消耗，从而将节省出的内存留给页缓存使用，更进一步地提升了整体性能。

#### 2.6.5 Kafka集群

Kafka的集群依赖于zookeeper。

如：Broker 列表管理**、**Partition 与 Broker 的关系**、**Partition 与 Consumer  的关系**、**Producer 与 Consumer 负载均衡**、**消费进度 Offset 记录**、**消费者注册 等，所以为了达到高可用，ZooKeeper 自身也必须是集群。

在Kafka 集群中，没有 “中心主节点” 的概念，集群中所有的节点都是对等的。

#### 2.6.6 Kafka负载均衡

Kafka的集群依赖于zookeeper。

ZooKeeper负载均衡实现：

- 每当一个Broker启动时，会首先完成Broker注册过程，在ZooKeeper的节点列表里保存Broker。
- Kafka的生产者会对ZooKeeper上的“Broker的新增与减少”、“Topic的新增和减少”和“Broker和Topic关联关系的变化”等事件注册Watcher监听
- 通过ZooKeeper的**Watcher通知能够让生产者动态的获取Broker和Topic的变化情况**
- Kafka有**消费者分组**的概念，每个消费者分组包含了若干个消费者，每一条消息只会发送给分组内的一个消费者，不同消费者分组消费自己特定的Topic下面的消息，互不干扰
- Kafka会为每个消费者**分配全局唯一的Consumer ID**，采用“Hostname：UUID”形式来表示
- 每个消费者一旦确定了对一个消息分区的消费权利，ZooKeeper会将其Consumer ID写入到对应消息分区的临时节点上
- 消费进度管理：**Kafka需要定时地将分区消息的消费进度，即Offset记录到ZooKeeper上去**


#### 2.6.7 Kafka使用实例

Kafka的应用，解决大量日志传输的问题。

- 日志采集客户端：负责日志数据采集，定时写入Kafka队列。

- kafka消息队列：负责日志数据的接收，存储和转发。

- 日志处理应用：订阅并消费kafka队列中的日志数据。

  


### 2.7 ActiveMQ

- 一个比较老牌的消息中间件，据说挺多小公司都在用。主要是用来做异步和削峰。


- 支持事务。在对应消在息队列中，事务就是多条消息一起发送，要么全部成功，要么全部失败。RabbitMQ和Kafka为了更高的性能，而放弃了对事物的支持 ，只有ActiveMQ支持。




### 2.8 消息队列应用

• 消息队列在项目中的应用

**1. 分布式事务：**

1）A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了

2）如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉mq发送确认消息，如果失败就告诉mq回滚消息

3）如果发送了确认消息，那么此时B系统会接收到确认消息，然后执行本地的事务

4）mq会自动定时轮询所有prepared消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认消息？那是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，别确认消息发送失败了。

5）这个方案里，要是系统B的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚；或者是发送报警由人工来手工回滚和补偿。

```
一些大佬给的建议不要做分布式事务，直接就是监控（发邮件、发短信）、记录日志（一旦出错，完整的日志）、事后快速的定位、排查和出解决方案、修复数据。这样比你做50个分布式事务，成本要来的低上百倍，低几十倍。
所以要用分布式事务的时候要权衡，分布式事务一定是有成本，代码会很复杂，开发很长时间，性能和吞吐量下跌，系统更加复杂更加脆弱反而更加容易出bug；但是好处就是如果做好了TCC、可靠消息最终一致性方案，一定可以100%保证你那快数据不会出错。
```



**2.日志处理：**






## 3.nginx

nginx最主要包括三个模块：main、 events 、 http。

### 3.1 配置反向代理

正向代理的代理对象是客户端，即正向代理隐藏了客户端的信息，代替客户端去向服务器请求资源。

反向代理的代理对象是服务端，即反向代理隐藏了服务端的信息，代替服务端向客户端返回资源。

 Nginx的反向代理是通过配置 **proxy_pass**来实现。

就是通过配置监听端口和location，使满足条件的请求能走到proxy_pass后的代理地址。

```
#Nginx用做反向代理时的简单配置如下：
server {
    listen       80;
    server_name  localhost;
    location / {
        proxy_pass  http://localhoot:8080;
    }
}
```

### 3.2 配置负载均衡

客户端向服务器发送的、nginx接收到的请求数量，就是我们说的负载量。

将请求数量按照一定的规则进行分发到不同的服务器处理的规则，就是一种均衡规则。

所以负载均衡就是：**将服务器接收到的请求按照规则分发的过程。**

nginx支持的负载均衡调度算法有：轮询、ip_hash、fair、url_hash。

nginx中，只要简单的配置 upstream模块和修改 proxy_pass，就能够实现负载均衡。

```
#Nginx用做负载均衡时的简单配置如下：
upstream loadBalanceTest { 
    server localhost:8081;  
    server localhost:8082;  
}
server {
    listen       80;
    server_name  localhost;
    location / {
        proxy_pass http://loadBalanceTest; 
    }
}
```

### 3.3 配置缓存

nginx可以通过设置Http缓存的方式提高访问效率，是一种服务器缓存。

Http缓存主要针如css，js，图片等更新频率不大的静态文件。

配置了Http缓存后，在缓存时间内访问同一个静态资源，nginx可以直接把资源从缓存中取出并返回，不会再去请求后台。

nginx配置缓存是通过配置 **proxy_cache** 模块相关的参数来实现。

```
#Nginx用做HTTP缓存时的简单配置如下：
proxy_cache_path /usr/local/nginx/tmpcache levels=1:2 keys_zone=mycache:10m max_size=200m inactive=60m;
server {
    listen       80;
    server_name  localhost;

    location / {
        proxy_pass http://loadBalanceTest;
        proxy_cache mycache;
        proxy_cache_valid 200 304 30m;
        proxy_cache_valid any 10m;
        #add_header my_cache " cache test: $upstream_cache_status";
    }
}
```



### 3.4 配置限流

- `limit_req_zone` 用来限制单位时间内的请求数，即速率限制，采用的漏桶算法 "leaky bucket"。
- `limit_req_conn` 用来限制同一时间连接数，即并发限制。

如可以通过rate参数设置访问速率，通过burst参数设置处理突发流量，通过nodelay参数允许请求在排队的时候就被处理。

配置限流后可以一定程度上阻止dos攻击。

```
#定义一个名为allips的limit_req_zone用来存储session，大小是10M内存，
#以$binary_remote_addr 为key,限制平均每秒的请求为20个，1M能存储16000个状态，rete的值必须为整数，
#如果限制两秒钟一个请求，可以设置成30r/m
limit_req_zone $binary_remote_addr zone=allips:10m rate=20r/s;
server{
    location {
        #限制每ip每秒不超过20个请求，漏桶数burst为5
        #brust的意思就是，如果第1秒、2,3,4秒请求为19个，第5秒的请求为25个是被允许的。
        #但是如果你第1秒就25个请求，第2秒超过20的请求返回503错误。
        #nodelay，如果不设置该选项，严格使用平均速率限制请求数，第1秒25个请求时，5个请求放到第2秒执行，
        #设置nodelay，25个请求将在第1秒执行。
        ...
        limit_req zone=allips burst=5 nodelay;
    }
}
```



### 3.5 Ngxin常用功能

**Nginx是一款轻量级的Web 服务器，也可以用做反向代理、负载均衡、动静分离和 HTTP缓存**。还可做如下功能：

#### gzip压缩作用

gzip on #开启gzip压缩
gzip_min_length 1k; #最小压缩大小，大于1k才压缩
gzip_http_version 1.1 #/压缩协议版本
gzip_comp_level 3 #压缩级别，1-10，数字越大压缩的越好，时间也越长
gzip_types  #压缩类型，根据/usr/local/nginx/conf/mime.types中定义，可以自己补;


#### Nginx 防盗链

盗链，就比如我的某个视频下载地址被其他网站引用，我们要禁止这种引用就叫做防盗链。

nginx中可以通过开通白名单的方式做防盗。

```
#rmvb|jpg|png|swf|flv表示对rmvb|jpg|png|swf|flv后缀的文件实行防盗链
location ~* \.(rmvb|jpg|png|swf|flv)$ {
            valid_referers none blocked  www.dbspread.com; #表示对www.dbspread.com此域名开通白名单
            root   html/b;
            if ($invalid_referer) { 
            	#如果请求不是从www.dbspread.com白名单发出来的请求，直接重定向到403.html这个页面或者返回403 
                 #rewrite ^/ http://www.dbspread.com/403.html;
                 return 403;
            }
    }

```

#### Nginx 防代理

```
#这三句if是禁止使用代理ip来访问，或禁止使用压力测试软件进行dos攻击（放在nginx.conf的server里面）
if ($http_user_agent ~* ApacheBench|WebBench|java/){
	return 403;
}
if ($http_user_agent ~* (Wget|ab) ) {
   return 403;
}
if ($http_user_agent ~* LWP::Simple|BBBike|wget) {
	return 403;
}
```

#### Nginx动态服务器

nginx用做静态资源服务器我们已经知道了，Nginx也能用做动态资源服务器。比如Nginx通过Lua语言就可以动态生成 html页面等，这样就相当于是一个动态资源服务器了！

```
OpenResty 就是一个基于 NGINX 的可伸缩的 Web 平台，由中国人章亦春发起，提供了很多高质量的第三方模块。OpenResty 是一个强大的 Web 应用服务器，Web 开发人员可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块,更主要的是在性能方面，OpenResty可以 快速构造出足以胜任 10K 以上并发连接响应的超高性能 Web 应用系统。
360，UPYUN，阿里云，新浪，腾讯网，去哪儿网，酷狗音乐等都是 OpenResty 的深度用户。
```

#### Nginx内容过滤器

有时候我们想对响应（例如PHP接口）返回的内容做些字符串，虽然可以使用各语言代码相关方法（例如PHP的`str_replace`）进行替换，但是在nginx层面替换是更方便的，无需修改代码。这里添加 `replace-filter-nginx-module` 模块。

#### Nginx状态信息

nginx中的stub_status模块主要用于查看Nginx的一些状态信息。需要安装`http_stub_status_module`模块

返回各数据项说明：

- Active connections：当前nginx正在处理的活动连接数。
- Server accepts handled requests request_time：nginx总共处理了13057 个连接,成功创建13057 握手(证明中间没有失败的)，总共处理了11634 个请求，总共请求时间2230854。
- Reading：nginx读取到客户端的Header信息数。
- Writing：nginx返回给客户端的Header信息数。
- Waiting：开启keep-alive的情况下,这个值等于 active – (reading + writing),意思就是nginx已经处理完成,正在等候下一次请求指令的驻留连接。

所以，在访问效率高，请求很快被处理完毕的情况下，Waiting数比较多是正常的。如果reading +writing数较多，则说明并发访问量非常大，正在处理过程中。



### 3.6 Nginx原理

首先要明白，Nginx 采用的是多进程（单线程） & 多路IO复用模型。使用了 **I/O 多路复用技术**的 Nginx，就成了”并发事件驱动“的服务器。

Nginx 启动时，会生成两种类型的 进程，一个 主进程（master），一个或多个工作进程（worker）。

主进程（master）充当整个进程组与用户的交互接口，同时对进程进行监护。它不需要处理网络事件，不负责业务的执行，只会通过管理worker进程来实现重启服务、平滑升级、更换日志文件、配置文件实时生效等功能。

Nginx 可以配置多个 worker，一般配置与cpu核数相同的worker线程即可，每个worker进程上可以支持数以万计的连接。这些worker进程从不会在网络上停止，每个新连接都会创建一个文件描述符，并消耗工作进程中少量的额外内存，每一个连接的额外消耗都很少。

当Nginx处理一个来自client的请求时，由master线程将请求转派到某个worker进程，当这个 worker 进程在 accept() 这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接。实际上就是根据请求头的host、ip和port来确定由哪个server处理，确定了server之后，再依据请求的uri找到相应的location。这个请求就由这个location处理。一个请求，完全由 worker 进程来处理，而且只能在一个 worker 进程中处理。

**epoll() 模型允许我们只在事件发生时才将控制返回给程序，而其他时候内核都挂起进程，随时待命。**

**这样，基于多进程+epoll， Nginx 便能实现高并发。**


•	在 x Nginx 中，如何使用未定义的服务器名称来阻止处理请求? ?
•	使用“ 反向代理服务器 ” 的优点是什么? 
•	x Nginx 服务器上的 r Master 和 和 r Worker 进程分别是什么? 
•	nginx的压力测试，你测试过吗，能抗住多少压力
•	你如何通过不同于 0 80 的端口开启 Nginx?
•	是否有可能将 x Nginx 的错误替换为 2 502 错误、 503
•	s stub_status 和 和 r sub_filter 指令的作用是什么? ?

## 4.netty

## 5.zk

## 6.dubbo

•	原理，怎么用
•	和erueka有什么区别
•	为什么要用dubbo，不用行不行？
•	跨域请求的一些知识点
•	Dubbo 支持哪些协议，每种协议的应用场景，优缺点？
•	Dubbo 超时时间怎样设置？
•	Dubbo 集群的负载均衡有哪些策略
•	Dubbo 的主要应用场景？
•	Dubbo 服务注册与发现的流程？
•	Dubbo 中 中 zookeeper 做注册中心，如果注册中心集群都挂掉，发布者和订阅者之间还能通信么？
•	dubbo 服务负载均衡策略？



# 五、其他插件

## 1.tomcat

### 1.1 tomcat架构

![img](https://upload-images.jianshu.io/upload_images/3433091-9ee5c3e4b85824a8.png?imageMogr2/auto-orient/strip|imageView2/2/w/882/format/webp)

由tomcat的架构图可知，tomcat结构如下：

```yaml
Server: 
  -Service: 
    -Connector: 
    -Engine:
       -Host:
         -Context:
		   -WebApp: 
		     -Filter
			 -Servlet
			 -POJO
```

#### 1.1.1 Server组件

​	`Tomcat`的一个实例，通常一个`JVM`只能包含一个`Tomcat`实例；因此，一台物理服务器上可以在启动多 个`JVM`的情况下在每一个`JVM`中启动一个`Tomcat`实例，每个实例分属于一个独立的管理端口。它的作用是：

- 提供监听器机制，用于在整个`Tomcat`生命周期中对不同的事件进行处理。
- 监听某个端口以接收`SHUTDOWN`命令。

```xml
<Server port="8005" shutdown="SHUTDOWN">
  <Listener className="org.apache.catalina.startup.VersionLoggerListener" /> ...
  <GlobalNamingResources> ... </GlobalNamingResources>
  <Service name="Catalina"> ... </Service>
</Server>
```

#### 1.1.2 Service组件

​	一个`Service`组件通常包含多个用于接收客户端消息的`Connector`组件和一个处理请求的`Engine`组件。不同的`Connector`组件使用不同的通信协议，如`HTTP`协议和`AJP`协议（AJP协议可以与一个web容器进行交互），此外还包含了若干个`Executor`组件，每个`Executor`都是一 个线程池，它可以为`Service`内所有组件提供线程池。

```xml
<Service name="Catalina">
	<Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" />
  	<Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />
  	<Engine name="Catalina" defaultHost="localhost">...</Engine>
</Service>
```

#### 1.1.3 Connector组件

​	**主要的职责就是接收客户端连接并接收消息报文**，消息报文经由它解析后送往`Engine`组件处理。因为存在不同的通信协议所以我们需要不同的`Connector`组件，每种协议对应一个`Connector`组件，目前`Tomcat8`包含`HTTP`和`AJP` 两种协议的`Connector`。`Connector`组件内部实现也会根据网络`I/O`的不同分为阻塞`I/O`和非阻塞`I/O`。

```xml
<Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" />
<!-- <Connector executor="tomcatThreadPool"
               port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /> -->
<!-- <Connector port="8443" protocol="org.apache.coyote.http11.Http11NioProtocol"
               maxThreads="150" SSLEnabled="true" scheme="https" secure="true"
               clientAuth="false" sslProtocol="TLS" /> -->
<Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />
```

**`Tomcat`内部有4个级别的容器，分别是`Engine`、`Host`、`Context`、`Wrapper`。**

#### 1.1.4 Engine组件

Engine代表全局Servlet引擎，每 个Service组件只能包含一个Engine，Engine包含如下组件：

- `Host`组件：虚拟主机，这些虚拟主机可以存放若干`Web`应用的抽象（`Context`容器）。
- `Realm`组件：提供了`Engine`容器级别的用户-密码-权限的数据对象，配合资源认证模块使用。

```xml
<Engine name="Catalina" defaultHost="localhost">
	<Realm className="org.apache.catalina.realm.LockOutRealm">...</Realm>
  	<Host name="localhost"  appBase="webapps" ...>...</Host>
</Engine>
```

```
Engine组件除了Host组件，还包含以下组件：
Listener组件（监听）、AccessLog组件（日志）、Pipeline组件（管道）、Realm组件（认证）、Cluster组件（集群）；
```

#### 1.1.5 Host组件

​	`Tomcat`中`Host`组件代表虚拟主机，这些虚拟主机可以存放若干`Web`应用的抽象(`Context`容器)。

```xml
<Host name="localhost"  appBase="webapps"
      unpackWARs="true" autoDeploy="true">

     <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs".../>
</Host>
```

```
Host组件除了context组件，还包含以下组件：
Listener组件（监听）、AccessLog组件（日志）、Pipeline组件（管道）、Realm组件（认证）、Cluster组件（集群）；
```

#### 1.1.6 Context组件

​	`Context`组件是`Web`应用的抽象，我们发开的`Web`应用部署到`Tomcat`后运行时就会转化成`Context`对象。它包含了各种静态资源、若干`Servlet`以及各种其他动态资源。

```
Context组件主要包含以下组件：
- Mapper组件：servlet映射器，它属于context内部的路由映射器，负责context容器的路由导航。
- Wrapper组件：Context子容器。
- Manager组件：会话管理器，用于管理Web容器的会话，包括维护会话的生成、更新、销毁。
- Loader组件：Web应用加载器，用于加载Web应用的资源，它要保证不同Web应用之间的资源隔离。
- NamingResource组件：命名资源，它负责将server.xml和web应用的context.xml资源映射到内存中。
- Listener组件（监听）、AccessLog组件（日志）、Pipeline组件（管道）、Realm组件（认证）；
```

#### 1.1.7 Wrapper组件

是`Tomcat4`个级别的容器中最小的，与之相对应的是`Servlet`，一个`Wrapper`对应一个`Servlet`。它主要包括如 下组件。

- `Servlet`组件：`Servlet`即`Web`应用开发中常用的`Servlet`，我们会在`Servlet`中编写好请求的逻辑处理。
- `ServletPool`组件：`Servlet`对象池，当`Web`应用的`Servlet`实现了。`SingleThreadModel`接口时则会在`Wrapper`中产生 一个`Servlet`对象池。线程执行时，需先从对象池中获取一个`Servlet`对象，`ServletPool`组件能保证`Servlet`对象的线程安全。
- `Pipeline`组件：`Wrapper`容器对请求进行处理的管道。

### 1.2 tomcat原理

Tomcat Server处理一个Http请求（localhost:8080/test/index.jsp）过程如下：

1. 用户点击网页内容，请求被发送到本机端口8080，被在那里监听的Coyote HTTP/1.1 Connector获得。
2. Connector把该请求交给它所在的Service的Engine来处理，并等待Engine的回应。
3. Engine获得请求localhost/test/index.jsp，匹配所有的虚拟主机Host。
4. Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机），名为localhost的Host获得请求/test/index.jsp，匹配它所拥有的所有的Context。Host匹配到路径为/test的Context（如果匹配不到就把该请求交给路径名为“ ”的Context去处理）。
5. path=“/test”的Context获得请求/index.jsp，在它的mapping table（通过Mapper组件）中寻找出对应的Servlet。Context匹配到URL PATTERN为*.jsp的Servlet,对应于JspServlet类。
6. 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet()或doPost()。执行业务逻辑、数据存储等程序。
7. Context把执行完之后的HttpServletResponse对象返回给Host。
8. Host把HttpServletResponse对象返回给Engine。
9. Engine把HttpServletResponse对象返回Connector。
10. Connector把HttpServletResponse对象返回给客户Browser。

```
即：Brower ->  HttpServletRequest -> Connector -> Connector所在的Service的Engine -> Host -> Context -> 
   Servlet -> doGet()/doPost() -> HttpServletResponse -> Context -> Host -> Engine -> Connector -> Brower
```



### 1.3 tomcat优化

#### 1.3.1 优化内存

Tomcat默认可以使用的内存为128MB，在较大型的应用项目中，这点内存是不够的。优化内存，主要是在bin目录下的catalina.bat /catalina.sh配置文件中添加 JAVA_OPTS，并在JAVA_OPTS中定义：

- 最小堆内存（-Xms，默认128MB），
- 最大堆内存（-Xmx），
- 每个线程堆栈的大小（-Xss）、
- 非堆内存（默认是物理内存的1/64，-XX:PermSize=200m; 或jdk8后 -XX:MetaspaceSize=200m）
- 最大非堆内存（-XX:MaxPermSize=256m; 或jdk8后 -XX:MaxMetaspaceSize=256m）

```
JAVA_OPTS="-server -Xms1G -Xmx2G -Xss256K -XX:PermSize=128M -XX:MaxPermSize=256m" 
```

#### 1.3.2 优化静态资源

静态页面缓存到Nginx。



#### 1.3.3 优化连接数

conf/server.xml文件中，Tomcat的Connector一些默认参数如下：

- **maxThreads：tomcat能起的最大线程数，默认是200**
- **maxProcessors：最大处理线程数，即：并发处理的最大请求数，默认值为75**
- **acceptCount：允许的最大连接数，应大于等于maxProcessors，默认值为100**
- **maxConnections：Tomcat任意时刻接收和处理的最大连接数，默认值为1000**


- minSpareThreads：tomcat最小空闲线程数，即初始线程数，默认值为
- maxSpareThreads：tomcat最大空闲线程数，超过的会被关闭
- minProcessors：最小空闲连接线程数，用于提高系统处理性能，默认值为10
- enableLookups：是否反查域名，取值为：true或false。为了提高处理能力，应设置为false

**可以根据实际情况适当加大一些配置，像我们项目一般会加大最大线程数到500。**

```
- tomcat8在Linux系统中，会自动选取使用NIO或APR（如果找到APR需要的本地库，则使用APR，否则使用NIO）。
- acceptCount：当客户端向服务器完成三次握手建立了连接，则该连接进入accept队列，队列满，则新进来的请求一律被拒绝。
- maxConnections：当Tomcat接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomcat接收的连接数小于maxConnections。如果设置为-1，则连接数不受限制。
- maxThreads：规定的是最大的线程数目，maxThreads的大小比CPU核心数量要大得多。这是因为，处理请求的线程真正用于计算的时间可能很少，大多数时间可能在阻塞，如等待数据库返回数据、等待硬盘读写数据等。因此，在某一时刻，只有少数的线程真正的在使用物理CPU，大多数线程都在等待；因此线程数远大于物理核心数才是合理的，让CPU忙碌起来，大大提高CPU的利用率。
```



•	设置线程数和多线程各个之间的区别



## 2.shiro

•	怎么做权限控制
•	为什么使用shiro，你直接使用aop不也是一样的吗，shiro还有标签~各种扯
•	shiro的两个最重要的函数
•	认证和授权是怎么做的



## 3.docker

•	和vmware的区别
•	你一般是怎么部署的 IDEA，直接把项目部署到docker并打包到云服务器
•	docker的好处，小，快

### 4.1 概念

​	docker是一种linux容器技术。容器有效的将由单个操作系统挂管理的资源划分到孤立的组中，以便更好的在组之间平衡有冲突的资源使用需求。可简单理解为一种沙盒 。每个容器内运行一个应用，不同的容器之间相互隔离，容器之间也可以建立通信机制。容器的创建和停止都十分快速，资源需求远远低于虚拟机。

与虚拟机比较：

|  特性   |    容器    |  虚拟机  |
| :---: | :------: | :---: |
| 启动速度  |    秒级    |  分钟级  |
| 硬盘使用  |  一般为MB   | 一般为GB |
|  性能   |   接近原生   |  弱于   |
| 系统支持量 | 单机支持千个容器 | 一般几十个 |
|  隔离性  |   安全隔离   | 安全隔离  |

**好处**

能高效地构建应用、高效的资源利用；对于运维开发来说，能快速的交付和部署，轻松的迁移扩展，简单的更新管理

**核心概念**

- **仓库（Repository）**：每个仓库存放某一类镜像。（Harbor：私有仓库，可以往其中上传镜像）
- **镜像（Image）**：类似虚拟机镜像，是一个只读的模板，一个独立的文件系统，包括运行容器所需的数据，可以用来创建新的容器。镜像可以基于`Dockerfile`构建，Dockerfile是一个描述文件，里面包含若干条命令，每条命令都会对基础文件系统创建新的层次结构。
- **容器（Container）**：Docker 利用容器来运行应用。Docker容器是由Docker镜像创建的运行实例。Docker容器类似虚拟机，可以支持的操作包括启动，停止，删除等。每个容器间是相互隔离的，容器中会运行特定的应用，包含特定应用的代码及所需的依赖文件。可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。

### **4.2 使用实例**

像我们之前就是用Gitlab +  Nexus + Jenkins + Harbor + Docker 的流水线打包。就是我们的代码提交到gitlab之后，同时更新我们的私服（deploy），然后 Jenkins 打包 maven 项目，构建 Docker 镜像及上传到Harbor，私有 docker 镜像库。（查看镜像：docker images、查看状态：docker ps、删除镜像：docker rmi）

![img](https://img2018.cnblogs.com/blog/1271786/201903/1271786-20190309200850820-485157958.png)



## 4.Maven

### 4.1 Maven依赖原则

#### 4.1.1 依赖路径最短优先原则

```
A -> B -> C -> X(1.0)
A -> D -> X(2.0)

```

由于 X(2.0) 路径最短，所以使用 X(2.0)。

#### 4.1.2 声明顺序优先原则

```
A -> B -> X(1.0)
A -> C -> X(2.0)

```

在 POM 中最先声明的优先，上面的两个依赖如果先声明 B，那么最后使用 X(1.0)。

#### 4.1.3 覆写优先原则

子 POM 内声明的依赖优先于父 POM 中声明的依赖。

### 4.2 解决依赖冲突

找到 Maven 加载的 Jar 包版本，使用 `mvn dependency:tree` 查看依赖树，根据依赖原则来调整依赖在 POM 文件的声明顺序。



# 六、Linux

### 1.常用命令

• 常见的命令

pwd、cd、ls、ll	路径相关

mkdir、touch、vi、vim、tar    建目录、建文件、打包

cp、scp、mv	、rm    复制、移动、删除文件

find、locate、whereis、which    查询文件，find（所有），locate（最近）、whereis（程序名）、which（可执行文件）

cat、head、tail、less、more、vi、vim 查看文件

ln 软连接（快捷方式）、硬链接（以文件副本的形式存在。但不占用实际空间），两种连接改变时源文件都会同时变化。

curl、wget    文件下载

ps、grep、kill    查看应用、关闭应用

top、free    查看进程、查看内存

sed、awd    编辑文本、处理文本

chmod、chown    授权、指定文件的用户或组、

jps、jstack    Java相关命令



### 2.Shell

**2.1 变量**

显示用` echo`、或`printf`

```shell
#shell定义变量
your_name="runoob.com"
#使用变量，只要在变量名前面加美元符号即可，可以加上花括号如：
echo $your_name
echo "your name is ${your_name}"
#使用循环
for skill in Ada Coffe Action Java; do
    echo "I am good at ${skill}Script"
done
#只读变量
myUrl="http://www.google.com"
readonly myUrl
myUrl="http://www.runoob.com"	#此句报错，因为是只读的
#删除变量
unset variable_name
#字符串操作
#1.拼接字符串
your_name="test"
greeting_2='hello, '$your_name' !'
#2.字符串长度
echo ${#your_name} #输出 4
#3.字符串提取
echo ${string:1:4} # 输出 字段内容（1-4包括）
```

**2.2 数组**

```shell
#创建数组
array_name=(value0 value1 value2 value3)
array_name[0]="newvalue0"
#读取数组
${数组名[下标]}
#数组长度
lengthn=${#array_name[n]}
```

**2.3 参数传递**

```shell
#参数传递
./test.sh 1 2 3
echo "Shell 传递参数实例！";
echo "执行的文件名：$0";	#输出：test.sh
echo "第一个参数为：$1";	#输出：1
echo "参数个数为：$#";	#输出：3
echo "传递的参数作为一个字符串显示：$*";	#输出：1 2 3
```

**2.4 运算符**

```shell
# 加减乘除余赋值：+ - \* / % =
a=10
b=20
val=`expr $a + $b`
echo "两数之和为 : $val"
# 条件表达式：== != ，
if [ $a == $b ]
# 关系运算符（只支持数字）：-eq  -ne	-gt	-lt	-ge	-le	
# 逻辑运算符：&&  ||
# 布尔运算符：!（非）  -o（或）  -a（与）
# 字符串运算符：=  !=  -z（长度为0）  -n（长度不为0）  $（不为空）
# 文件运算符：-r(可读)、-x（可执行）、-d（是目录）、-f（是文件） -e（存在）、-s（不为空）
```

**2.5 流程控制**

```shell
# if控制
if condition1
then
    command1
elif condition2 
then 
    command2
else
    commandN
fi
# for循环控制， 无限循环是：for (( ; ; ))
for loop in 1 2 3 4 5
do
    echo "The value is: $loop"
done
# while控制，无限循环是：while :  或者 while true 
while condition
do
    command
done
# 跳出同样是break、continue
```

**2.6 定义函数**

```shell
demoFun(){
    echo "这是我的第一个 shell 函数!，输入为: $1"
}
echo "-----函数开始执行-----"
demoFun "11"
echo "-----函数执行完毕----- 11"
```

**2.7 shell其他**

```shell
#输出重定向
command1 > file1  
#test2.sh中，使用 . 号来引用test1.sh 文件
. ./test1.sh
# 或者使用以下包含文件代码
# source ./test1.sh
echo "菜鸟教程官网地址：$url"
```



### 3.Linux其他点

**3.1 开机自启**

方法1：在/etc/rc.local中添加

方法2：init.d目录下都为可执行程序，他们其实是服务脚本，按照一定格式编写，Linux 在启动时会自动执行。

**3.2 页式存储**

​	linux中页缓存的本质就是对于磁盘中的部分数据在内存中保留一定的副本，使得应用程序能够快速的读取到磁盘中相应的数据，并实现不同进程之间的数据共享。

​	如果没有进程之间的共享机制，那么对于系统中所启动的所有进程在打开文件的时候都要将需要的数据从磁盘加载进物理内存空间，这样不仅造成了加载速度变慢（每次都从磁盘中读取数据），而且造成了物理内存的浪费。

**3.3 零拷贝**

​	“零拷贝技术”只用将磁盘文件的数据复制到页面缓存中一次，然后将数据从页面缓存直接发送到网络中（发送给不同的订阅者时，都可以使用同一个页面缓存），避免了重复复制操作。



•	sed 和 awk 感觉linux必考。。
•	打印一个文件夹中的所有文件
•	float在计算机中是怎么存储的，当时被问到的时候，我也在问自己，怎么存的~~~ 佛了
•	线程的通信方式，进程的通信方式
•	系统线程的数量上限是多少

•	内存碎片，你有了解过吗，有想过解决方案吗~



# 七、算法

## 1.排序算法概览

• 八大排序算法真的是面试宠儿，最常考 **快速排序 和归并排序**，堆排 也应该掌握，哪些排序算法是稳定的 哪些是不稳定的

**排序概念**：

​	对一序列对象根据某个关键字进行排序。

**排序说明**：

- **稳定**：如果a原本在b前面，而a=b，排序之后a仍然在b的前面；
- **不稳定**：如果a原本在b的前面，而a=b，排序之后a可能会出现在b的后面；
- **内排序**：所有排序操作都在内存中完成；
- **外排序**：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行；
- **时间复杂度：** 一个算法执行所耗费的时间。时间：O(1) < O(logn) < O(n) < O(nlogn) < O(n^2) < O(n^2logn)  < O(n^3)
- **空间复杂度**：运行完一个程序所需内存的大小。

**排序总结：**

| **排序算法** |  是否稳定  |        时间复杂度        |  空间复杂度   |
| :------: | :----: | :-----------------: | :------: |
| **冒泡排序** |   稳定   |       O(n^2)        |   O(1)   |
| **选择排序** |  不稳定   |       O(n^2)        |   O(1)   |
|   插入排序   |   稳定   |       O(n^2)        |   O(1)   |
|   希尔排序   |  不稳定   | 平均O(n^1.3)，最坏O(n^2) |   O(1)   |
|   快速排序   |  不稳定   | 平均O(nlogn)，最坏O(n^2) | O(logn)  |
| **归并排序** | **稳定** |    **O(nlogn)**     | **O(n)** |
|   堆排序    |  不稳定   |      O(nlogn)       |   O(1)   |
|   桶排序    |   稳定   |  平均O(n+k)，最坏O(n^2)  |  O(n+k)  |
|   计数排序   |   稳定   |       O(n+k)        |   O(k)   |

```
Arrays.sort()中：
长度<47：插入排序（时间：O(n^2)，空间：O(1)）；
长度<286：快速排序（时间：O(logn)-O(n^2)，空间：O(logn)）；
长度>=286：并归排序（时间：O(logn)，空间：O(n)）
```

### 1.1 冒泡排序

- 冒泡排序，即重复比较相邻的元素。如果第一个比第二个大，就交换它们两个；从开始第一对到结尾的最后一对；
- 冒泡排序的时间复杂度都是O(n^2)，空间复杂度O(1)；
- 直接选择排序中，如果左右两个元素相等，则不会交换。所以是稳定的。

```java
 public static void bubbleSort(int[] a) {
 	for (int i = 0; i < a.length; i++) {
 		for (int j = 0; j < a.length - 1 -i; j++) {
 			if(a[j] > a[j+1]) {
 				int tmp = a[j];
 				a[j] = a[j+1];
 				a[j+1] = tmp;
 			}
		 }
 	}
 }
```

### 1.2 选择排序

- 也称直接选择排序，即每次从当前待排序的区间中选择出最小的元素，把该元素与该区间的第一个元素交换；
- 直接选择排序的时间复杂度为O(n^2)；
- 直接选择排序中存在着前后元素之间的互换，导致改变具有相同排序码元素的前后相对位置，所以是不稳定的。

```java
 public static void selectSort(int[] a) {
 	for (int i = 0; i < a.length - 1; i++) {
 		for (int j = i + 1; j < a.length; j++) {
 			if(a[i] > a[j]) {
 				int tmp = a[i];
 				a[i] = a[j];
 				a[j] = tmp;
 			}
		 }
 	}
 }
```

### 1.3 插入排序

- 插入排序的核心思想是：维护一个有序区，把元素一个一个插入到有序区的适当位置，直到所有元素有序为止。
- 插入排序的时间复杂度为O(n^2)；
- 稳定

```java
public static void insertSort(int[] arr) {
	for (int i = 1; i < arr.length; i++) {
      	//待插入值
	    int insertValue = arr[i];
         int j = i - 1;
      	 //待插入值与有序区的值持续比较
         while (j >= 0 && arr[j] > insertValue) {
           	 //若有序区的值比待插入值大，则有序区的值右移
         	 arr[j + 1] = arr[j];
           	 //为插入做准备
             j--;
         }
      	 //待插入值放到合适的位置
         arr[j + 1] = insertValue;
	 }
}
```

### 1.4 希尔排序

- 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。
- 时间复杂度平均：O(N^1.3)，最坏O(n^2)，空间复杂度：O(1)
- 不稳定

```java
private static void shellSort(int[] arr) {
    //gap目的是先让大多数元素有序，gap等于1时就是完全的插入算法
    int gap = arr.length / 2;
    while (gap >= 1) {
        for (int i = gap; i < arr.length; i++) {
            int insertValue = arr[i];
            int j = i - gap;
            while (j >= 0 && arr[j] > insertValue) {
                arr[j + gap] = arr[j];
                j = j - gap;
            }
            arr[j + gap] = insertValue;
        }
        gap = gap / 2;
    }
}
```

### 1.5 快速排序

- 快速排序，即先选一个基准元素（Pivot），然后把其他元素中把比基准元素小的移到一变，把比基准元素大的移到另一半。然后持续对这两部分记录拆分和移动，直到不可再分为止。（分治法）
- 快速排序的平均时间复杂度为O(nlogn)，最坏为O(n^2)，代价是需要额外的内存空间O(logn)。
- 不稳定

```java
public static void quickSort(int[] arr, int startIndex, int endIndex) {
	// 递归结束条件：开始的位置>=结束的位置
	if (startIndex >= endIndex) {
		return;
	}
	// 得到基准元素的位置
	int pivotIndex = partition(arr, startIndex, endIndex);
	// 用分治法递归数列的两部分
	quickSort(arr, startIndex, pivotIndex - 1);
	quickSort(arr, pivotIndex + 1, endIndex);
}

private static int partition(int[] arr, int startIndex, int endIndex) {
	//坑的位置，初始等于起点位置，起点位置的元素作为基准元素
	int pivotIndex = startIndex;
	int pivot = arr[pivotIndex];
 	//定义左右的位置
	int left = startIndex;
	int right = endIndex;
	// 大循环在左右指针重合或者交错时结束，目的是把小于基准元素的放到左边，大于基准元素的放到右边
	while (right >= left) {
		/** right指针从右向左进行比较
		 * 如果right处的元素比基准元素小,则：
		 * 把right处的元素移入坑中，right作为坑，
		 * 同时，left向右移动一位，此时left左边的区域代表小于基准元素的区域
		 */
		while (right >= left) {
			if (arr[right] < pivot) {
				arr[left] = arr[right];
				pivotIndex = right;
				left++;
				break;
			}
			/* 如果right处的元素比基准元素大，继续向左比较*/
			right--;
		}

		/** left指针从左向右进行比较
		 * 如果left处的元素比基准元素大,则：
		 * 把left处的元素移入坑中，left作为坑，
		 * 同时，right向左移动一位，此时right右边的区域代表大于基准元素的区域
		 */
		while (right >= left) {
			if (arr[left] > pivot) {
				arr[right] = arr[left];
				pivotIndex = left;
				right--;
				break;
			}
			left++;
		}
	}
	/* 最后把坑的元素放回坑，并返回坑的位置 */
	arr[pivotIndex] = pivot;
	return pivotIndex;
}
```



### 1.6 归并排序

- 归并排序，先对集合持续分组，分到不可再分（每组元素只有一个）；然后再合并，合并就是每个组内部先排好序，小组之间再进一步比较和排序，合并成一个大的组。大组之间继续比较和排序，再合并成更大的组，最终合并成有序集合。（分治法）
- 归并排序的时间复杂度始终都是O(nlogn)，代价是需要额外的内存空间O(n)。
- 稳定。


```java
private static void mergeSort(int[] arr, int start, int end) {
        // 递归结束条件：开始的位置>=结束的位置
        if (start >= end) {
            return;
        }
        int mid = (start + end) / 2;
        mergeSort(arr, 0, mid); //排左边的序
        mergeSort(arr, mid + 1, end);   //排右边的序
        merge(arr, start, mid, end);    //合并

    }

    private static void merge(int[] arr, int start, int mid, int end) {
        //开辟额外的大集合，用于合并数据
        int[] tmpArr = new int[end - start + 1];
      	//左侧小集合起点
        int p1 = start;
      	//右侧小集合起点
        int p2 = mid + 1;
      	//大集合起点
        int p = 0;
        //比较两个小集合的元素，一次放入大集合
        while (p1 <= mid && p2 <= end) {
            if (arr[p1] > arr[p2]) {
                tmpArr[p++] = arr[p2++];
            } else {
                tmpArr[p++] = arr[p1++];
            }
        }
        //左侧小集合还有剩余，依次放入大集合尾部
        while (p1 <= mid) {
            tmpArr[p++] = arr[p1++];
        }
        //右侧小集合还有剩余，依次放入大集合尾部
        while (p2 <= end) {
            tmpArr[p++] = arr[p2++];
        }
        //把大集合中的元素复制回原数组
        for (int i = 0; i < tmpArr.length; i++) {
            arr[i + start] = tmpArr[i];
        }
    }
```



### 1.7 堆排序





> 非比较排序时间复杂度低，但由于非比较排序需要占用空间来确定唯一位置。所以对数据规模和数据分布有一定要求。

### 1.8 计数排序

- 计数排序需要占用大量空间，它仅适用于数据比较集中的情况。比如 [0~100]，[10000~19999] 这样的数据。如果数列最大值和最小值差距过大，就不适用。且只使用于整数。
- 计数排序时间复杂度为O(n+k)，空间复杂度为O(k)
- 稳定

```java
private static int[] countSort(int[] arr) {
    //1.得到数组的最大最小值
    int max = arr[0];
    int min = arr[0];
    for (int i = 1; i < arr.length; i++) {
        max = (arr[i] > max) ? arr[i] : max;
        min = (arr[i] < min) ? arr[i] : min;
    }
    //2.创建统计数组并统计对应元素个数。（如2-6，数组长度为5）
    int[] countArr = new int[max - min + 1];
    for (int i = 0; i < arr.length; i++) {
        int pos = arr[i] - min;
        countArr[pos]++;
    }

    //3.计算每个数字应该在结果数组的位置。是这个位置之前有几位的意思。
    for (int i = 1; i < countArr.length; i++) {
        countArr[i] = countArr[i - 1] + countArr[i];
    }

    //4.倒序遍历原始数组，从统计数组找到正确位置，输出到结果数组
    int[] resArr = new int[arr.length];
    for (int i = arr.length - 1; i >= 0; i--) {
        int cpos = arr[i] - min;
        resArr[countArr[cpos] - 1] = arr[i];
        countArr[cpos]--;
    }
    return resArr;
}
```



### 1.9 桶排序

- 桶排序是将待排序集合中处于同一个值域的元素存入同一个桶中，也就是根据元素值特性将集合拆分为多个区域，则拆分后形成的多个桶，从值域上看是处于有序状态的。对每个桶中元素进行排序，则所有桶中元素构成的集合是已排序的。（桶排序中很重要的一步就是桶的设定，尽量均匀的放入不同的桶，如果只有一个桶，那就容易O(n^2)了）
- 桶排序时间复杂度为O(n+k)，空间复杂度为O(k)
- 稳定

```java
private static void bucketSort(int[] arr) {
    // 新建一个桶集合，桶内元素会频繁的插入，所以选择 LinkedList
    ArrayList<LinkedList<Integer>> bucketList = new ArrayList<>();
    // 往桶集合中添加n个桶，（桶数量根据需要来）
    int n = 10;
    for (int i = 0; i < n; i++) {
        bucketList.add(new LinkedList<>());
    }
    // 将输入数据全部放入桶中并完成排序
    for (int data : arr) {
        int index = getBucketIndex(data);
        insertSort(bucketList.get(index), data);
    }
    // 将桶中元素全部取出来并放入 arr 中输出
    int index = 0;
    for (LinkedList<Integer> bucket : bucketList) {
        for (Integer data : bucket) {
            arr[index++] = data;
        }
    }
}

/**
 * 对于单个桶，可以使用不同的排序方法。如使用插入排序、或者快速排序等。
 */
private static void insertSort(LinkedList<Integer> bucket, int data) {
    ListIterator<Integer> it = bucket.listIterator();
    boolean insertFlag = true;
    while (it.hasNext()) {
        if (data <= it.next()) {
            it.previous(); // 把迭代器的位置偏移回上一个位置
            it.add(data); // 把数据插入到迭代器的当前位置
            insertFlag = false;
            break;
        }
    }
    if (insertFlag) {
        bucket.add(data); // 否则把数据插入到链表末端
    }
}

/**
 * 计算得到输入元素应该放到哪个桶内
 */
private static int getBucketIndex(int data) {
    //举例，需要根据场景，以使不同元素落到不同桶中
    return data / 10;
}
```



### 



## 2.树

•	根据遍历结果恢复树，递归
•	二叉搜索树第k大
•	树的和为k的路径
•	层次遍历
•	根据层次遍历和后序遍历恢复树
•	镜像树
•	树的深度
•	是不是平衡二叉树

## 3.链表

•	反转链表
•	链表环的入口
•	交叉链表的交点
•	复杂链表的复制
•	二叉搜索树变成双向链表

## 4.回溯算法

•	走迷宫
•	游戏通关

## 5.递推算法

•	走台阶
•	断钢筋

## 6.背包问题

•	装最多的东西

## 7.贪心算法

•	覆盖问题
•	时间问题

# 八、设计模式

面试中设计模式其实也是挺重要的

## 1.单例模式

• Java 中什么叫单例设计模式？请用 Java 写出线程安全的单例模式



## 2.代理模式

静态代理：

代理对象和目标对象实现同一个接口，且代理对象持有目标对象的引用，所以在共同的实现方法中，可以在代理方法前后添加一些其它操作，即帮忙做一些目标对象做不了或不想做的事情。



## 3.观察者模式



## 4.适配器模式

•	生产者消费者模式，要求手写过代码，还是要知道的
•	单例模式，饿汉式，懒汉式，线程安全的做法，两次判断instance是否为空，每次判断的作用是什么。
•	在 Java 中，什么叫观察者设计模式（observer design pattern）
•	使用工厂模式最主要的好处是什么？在哪里使用
•	举一个用 Java 实现的装饰模式(decorator design pattern) ？它是作用于对象层次还是类层次？ 


# 九、其他问题

## 1.自我介绍？

### 1.1介绍基本信息

​	如：您好，我叫李春龙，来自广西，毕业于广西大学，今年26岁。

### 1.2 介绍项目经验

​	从2015年开始，，，（介绍一些工作经验），然后自觉市面上一些常用的技术还是比较了解的。（暗示自己技术可以）

### 1.3 介绍个人目标

​	我的目标是成为一名合格的架构师，我也一直在往这个方向努力靠近。（表明你是一个有追求的人）

### 1.4 表达向往

​	如：我在招聘网上/经朋友推荐/..了解到贵公司，看到岗位的一些要求我还是比较符合的，所以现在来试一下看看有没有合作的可能。（表示你希望合作）



## 2.最难问题？

见仁见智。就说刚开始什么都不会，然后拼命学拼命学，然后结果还不错。然后表示相信自己可以解决很多问题。



## 3.项目架构？

像公租房那个的话，就是分为了

- 公共模块：提供公共服务，像提供一些公用实体、工具类之类的。
- 文件处理模块：提供文件服务，像提供文件的上传下载之类的。(阿里云OSS)
- 日志模块：提供日志服务（基于Log4j2），包括错误日志、应用监控日志以及用户行为日志使用。像错误日志的话可以配置手机报警及存入es来供查看。
- 定时任务模块：提供分布式的定时任务。（elasticjob）
- 搜索服务：提供快速搜索，是用es来做的。
- 第三方服务模块：提供第三方的一些支持，像人脸识别，实名认证、微信/支付宝支付等对接。（Hession）
- 普通服务模块：主要是给Web端和APP端提供一些接口。
- 然后还分APP、Web、ADMIN这三个端的模块。

长春城市管理：

- 服务中心：
- 配置中心：
- 服务网关：
- 文件服务：
- 第三方服务：
- 公共服务：像common、各个子系统等。